
import asyncio
from sklearn import metrics
import websockets
import json
import time
import base64
import io
import wave
import numpy as np
import sounddevice as sd
import uvloop




# PHRASES = [
#     "Hello, this is a test message intended to evaluate the performance and latency of the real-time text-to-speech WebSocket service. By sending this extended phrase, we can better simulate the kind of longer, more complex input that might be generated by a large language model in a real-world application scenario.",
#     "How quickly can you respond to this request? I am interested in measuring not only the speed of your initial reply, but also the consistency and reliability of your responses when handling longer and more detailed sentences, as would be expected in a production environment.",
#     "Testing latency for LLM chunk simulation is crucial for understanding how the system performs under realistic conditions. This sentence is intentionally verbose, containing multiple clauses and descriptive language, to better approximate the output of a generative AI model during a live session.",
#     "This is the fourth phrase in our series of test inputs. It is designed to further challenge the system by providing a longer, more intricate sentence structure, which should help us observe how the WebSocket server manages streaming and audio chunking for extended text passages.",
#     "Final phrase for the test. This concluding message serves as a comprehensive evaluation of the end-to-end latency and audio playback quality, ensuring that the system can handle a full range of input complexities and maintain performance throughout the entire sequence of requests."
# ]

# PHRASES = [
#     # "In the rapidly evolving field of artificial intelligence, large language models have demonstrated remarkable capabilities in generating human-like text, understanding context, and assisting with a wide range of tasks across various domains.",
#     # "These models, trained on vast amounts of data, are able to produce coherent and contextually relevant responses, making them invaluable tools for research, business, and creative applications.",
#     # "However, as with any technology, there are challenges to address, including ethical considerations, bias mitigation, and ensuring responsible deployment.",
#     # "As we continue to explore the potential of these systems, it is crucial to balance innovation with caution, fostering an environment where AI can be developed and used for the benefit of all.",
#     # "Ultimately, the future of AI will depend on our collective efforts to guide its growth in a direction that aligns with societal values and priorities.",
#     "This",
#     "is",
#     "an",
#     "example",
#     "of",
#     "LLM",
#     "output",
#     "in",
#     "short",
#     "chunks.",
#     "A",
#     "B",
#     "C",
#     "D",
#     "E",
#     "F",
#     "G",
#     "H",
#     "I",
#     "J",
#     "K",
#     "L",
#     "M",
#     "N",
#     "O",
#     "P",
#     "Q",
#     "R",
#     "S",
#     "T",
#     "U",
#     "V",
#     "W",
#     "X",
#     "Y",
#     "Z",
#     "!",
#     ".",
#     "?"
# ]


WS_URL = "ws://localhost:8000/ws"  # Adjust port if needed

# Unified delay between sending each phrase (in seconds)
CHUNK_DELAY = 0


def play_wav_bytes(wav_bytes):
    with io.BytesIO(wav_bytes) as wav_io:
        with wave.open(wav_io, 'rb') as wf:
            sample_rate = wf.getframerate()
            channels = wf.getnchannels()
            sampwidth = wf.getsampwidth()
            frames = wf.readframes(wf.getnframes())
            dtype = {1: np.int8, 2: np.int16, 4: np.int32}[sampwidth]
            audio = np.frombuffer(frames, dtype=dtype)
            if channels > 1:
                audio = audio.reshape(-1, channels)
            sd.play(audio, samplerate=sample_rate)
            sd.wait()


class PhraseMetrics:
    def __init__(self, phrase):
        self.phrase = phrase
        self.send_time = None  # Time when phrase is sent
        self.first_chunk_time = None  # Time when first chunk is received
        self.end_time = None
        self.chunks = 0
        self.chunk_times = []
        self.total_bytes = 0

    def report(self):
        print(f"\n--- Metrics for: '{self.phrase}' ---")
        if self.first_chunk_time and self.send_time:
            print(f"  First chunk latency (send→recv): {self.first_chunk_time - self.send_time:.3f} s")
        if self.send_time and self.end_time:
            print(f"  Total time (send→final): {self.end_time - self.send_time:.3f} s")
        print(f"  Chunks received: {self.chunks}")
        print(f"  Total bytes: {self.total_bytes}")
        if self.chunk_times:
            print(f"  Per-chunk times (s since send): {[round(t,3) for t in self.chunk_times]}")

async def sender(phrases, websocket, phrase_queues, metrics_list, send_times):
    for i, phrase in enumerate(phrases):
        if i > 0:
            await asyncio.sleep(CHUNK_DELAY)
        metrics = PhraseMetrics(phrase)
        metrics_list.append(metrics)
        phrase_queues[phrase] = asyncio.Queue()
        send_time = time.perf_counter()
        metrics.send_time = send_time
        send_times[phrase] = send_time
        await websocket.send(phrase)


async def receiver(websocket, phrase_queues, metrics_list, send_times, audio_queue=None, play_audio=True):
    current_phrase_idx = 0
    complete_wav = b""
    sample_rate = 24000
    first_chunk = True
    phrase = PHRASES[current_phrase_idx]
    # Wait for metrics to be available for the first phrase
    while len(metrics_list) <= current_phrase_idx:
        await asyncio.sleep(0.001)
    metrics = metrics_list[current_phrase_idx]
    while True:
        try:
            response = await websocket.recv()
        except websockets.ConnectionClosed:
            break
        now = time.perf_counter()
        data = json.loads(response)
        if "audioOutput" in data:
            if first_chunk:
                metrics.first_chunk_time = now
                latency = metrics.first_chunk_time - metrics.send_time
                print(f"Phrase: '{phrase}' - First chunk latency (send→recv): {latency:.3f} s")
                first_chunk = False
            metrics.chunks += 1
            metrics.chunk_times.append(now - metrics.send_time)
            audio_b64 = data["audioOutput"]["audio"]
            audio_bytes = base64.b64decode(audio_b64)
            metrics.total_bytes += len(audio_bytes)
            complete_wav += audio_bytes
            sample_rate = data["audioOutput"].get("sampleRate", 24000)
        elif "finalOutput" in data:
            metrics.end_time = now
            if play_audio and audio_queue is not None:
                await audio_queue.put(complete_wav)
            # Move to next phrase
            current_phrase_idx += 1
            if current_phrase_idx >= len(PHRASES):
                break
            phrase = PHRASES[current_phrase_idx]
            # Wait for metrics to be available for the next phrase
            while len(metrics_list) <= current_phrase_idx:
                await asyncio.sleep(0.001)
            metrics = metrics_list[current_phrase_idx]
            complete_wav = b""
            first_chunk = True
        elif "error" in data:
            print(f"Error from server for '{phrase}':", data["error"])
            metrics.end_time = now
            # Move to next phrase
            current_phrase_idx += 1
            if current_phrase_idx >= len(PHRASES):
                break
            phrase = PHRASES[current_phrase_idx]
            # Wait for metrics to be available for the next phrase
            while len(metrics_list) <= current_phrase_idx:
                await asyncio.sleep(0.001)
            metrics = metrics_list[current_phrase_idx]
            complete_wav = b""
            first_chunk = True

async def audio_player(audio_queue):
    while True:
        wav_bytes = await audio_queue.get()
        if wav_bytes is None:
            break
        # Play audio in a background thread to avoid blocking the event loop
        await asyncio.to_thread(play_wav_bytes, wav_bytes)



async def main():
    print("Using uvloop for improved performance.")
    asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())
    metrics_list = []
    phrase_queues = {}
    send_times = {}
    audio_queue = asyncio.Queue()
    async with websockets.connect(WS_URL) as websocket:
        send_task = asyncio.create_task(sender(PHRASES, websocket, phrase_queues, metrics_list, send_times))
        recv_task = asyncio.create_task(receiver(websocket, phrase_queues, metrics_list, send_times, audio_queue=audio_queue))
        audio_task = asyncio.create_task(audio_player(audio_queue))
        await asyncio.gather(send_task, recv_task)
        await websocket.send("stop")
        # Signal audio player to exit
        await audio_queue.put(None)
        await audio_task

    print("\n==== Latency Metrics Summary ====")
    for metrics in metrics_list:
        metrics.report()

if __name__ == "__main__":
    asyncio.run(main())

if __name__ == "__main__":
    asyncio.run(main())